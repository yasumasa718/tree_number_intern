{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a4bf3a-f746-49ee-b0b7-29b3deabde4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ライブラリ、モジュールのインポート\n",
    "import os \n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import uuid  # ユニークな識別子を生成するためのモジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0453a2e-73ed-4d90-be16-c5ef59149201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUの設定ができています。\n"
     ]
    }
   ],
   "source": [
    "#GPUの確認\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "  print(\"GPUの設定ができています。\")\n",
    "else:\n",
    "  print(\"GPUの設定ができていません！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73204a5b-e5a4-46f5-96d0-963c5b707b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画像データが格納されたディレクトリパス\n",
    "image_data_path = \"/home/yasumasa-tezuka/data_intern/train_data/images\"\n",
    "# テキストデータが格納されたディレクトリパス\n",
    "text_data_path = \"/home/yasumasa-tezuka/data_intern/train_data/labels\"\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(640, scale=(0.8, 1.0)),  # ランダムにサイズ変更とクロップ\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # ランダムな水平反転\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # ランダムな垂直反転\n",
    "    transforms.RandomRotation(degrees=90),  # ランダムな回転（-90度から90度）\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # 色調の変更\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=15),  # アフィン変換\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),  # ランダムな透視変換\n",
    "    transforms.GaussianBlur(kernel_size=7, sigma=(0.1, 2.0)),  # ガウシアンぼかし\n",
    "    transforms.ToTensor(),  # PyTorchのテンソルに変換\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1c10ae2-8b7e-400e-b4c5-263b88b693a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ拡張1回目後のデータ数: 254\n",
      "データ拡張2回目後のデータ数: 508\n",
      "データ拡張3回目後のデータ数: 762\n",
      "データ拡張4回目後のデータ数: 1016\n",
      "データ拡張5回目後のデータ数: 1270\n",
      "データ拡張6回目後のデータ数: 1524\n",
      "データ拡張7回目後のデータ数: 1778\n",
      "データ拡張8回目後のデータ数: 2032\n",
      "データ拡張9回目後のデータ数: 2286\n",
      "データ拡張10回目後のデータ数: 2540\n",
      "データ拡張11回目後のデータ数: 2794\n",
      "データ拡張12回目後のデータ数: 3048\n",
      "データ拡張13回目後のデータ数: 3302\n",
      "データ拡張14回目後のデータ数: 3556\n",
      "データ拡張15回目後のデータ数: 3810\n",
      "データ拡張16回目後のデータ数: 4064\n",
      "データ拡張17回目後のデータ数: 4318\n",
      "データ拡張18回目後のデータ数: 4572\n",
      "データ拡張19回目後のデータ数: 4826\n",
      "データ拡張20回目後のデータ数: 5080\n"
     ]
    }
   ],
   "source": [
    "# トレーニングデータの新しいディレクトリパス\n",
    "train_data_dir = \"/home/yasumasa-tezuka/data_intern/train_data/images_expansion\"\n",
    "\n",
    "# ディレクトリが存在しない場合、作成\n",
    "if not os.path.exists(train_data_dir):\n",
    "    os.makedirs(train_data_dir)\n",
    "\n",
    "# 画像データのリスト\n",
    "image_files = glob.glob(os.path.join(image_data_path, \"*.jpg\"))  # 画像ファイルの拡張子に合わせて修正\n",
    "\n",
    "# テキストファイルのリストを作成（対応するテキストファイルのファイル名を生成）\n",
    "text_files = [os.path.join(text_data_path, os.path.splitext(os.path.basename(image_file))[0] + \".txt\") for image_file in image_files]\n",
    "\n",
    "# データ拡張を20回繰り返す\n",
    "for i in range(20):\n",
    "    # データ拡張とコピー\n",
    "    for image_file in image_files:\n",
    "        image = Image.open(image_file)\n",
    "        # データ拡張を適用\n",
    "        augmented_image = data_transforms(image)\n",
    "\n",
    "        # TensorをPILイメージに変換\n",
    "        augmented_image_pil = ToPILImage()(augmented_image)\n",
    "        \n",
    "        # 新しいファイル名を生成（例：元のファイル名 + ユニークな識別子 + 拡張子）\n",
    "        file_name = os.path.basename(image_file)\n",
    "        base_name_without_extension, extension = os.path.splitext(file_name)\n",
    "        unique_id = str(uuid.uuid4())[:8]  # ランダムな8文字の識別子\n",
    "        new_file_name = f\"{base_name_without_extension}_{unique_id}{extension}\"\n",
    "\n",
    "        # トレーニングデータディレクトリに保存\n",
    "        augmented_image_pil.save(os.path.join(train_data_dir, new_file_name))\n",
    "\n",
    "        # 対応するテキストファイルの名前を生成\n",
    "        text_file = os.path.join(text_data_path, base_name_without_extension + \".txt\")\n",
    "        new_text_file_name = os.path.basename(new_file_name)\n",
    "        new_text_file_name = os.path.splitext(new_text_file_name)[0] + \".txt\"\n",
    "\n",
    "        # トレーニングデータディレクトリにコピー\n",
    "        shutil.copy(text_file, os.path.join(train_data_dir, new_text_file_name))\n",
    "\n",
    "    # データ拡張後のデータ数\n",
    "    augmented_data_size = len(os.listdir(train_data_dir))\n",
    "\n",
    "    print(f\"データ拡張{i+1}回目後のデータ数:\", augmented_data_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a6eb57d-6ce4-4f96-ac7a-1ecf69b7cd38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練用 97\n",
      "検証用 33\n",
      "訓練用 97\n",
      "検証用 33\n"
     ]
    }
   ],
   "source": [
    "#アノテーションした画像データの取得\n",
    "data_path = \"/home/yasumasa-tezuka/data_intern/train_data/images/\"\n",
    "data_path_1 = \"/home/yasumasa-tezuka/data_intern/train_data/labels/\"\n",
    "\n",
    "x_list = glob.glob(data_path + \"*.jpg\") + glob.glob(data_path + \"*.JPG\")\n",
    "y_list = glob.glob(data_path_1 + \"*.txt\")\n",
    "\n",
    "if len(x_list) != len(y_list):\n",
    "    print(f\"警告: x_list と y_list の長さが一致していません（x_list: {len(x_list)}, y_list: {len(y_list)}）\")\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_list, y_list)\n",
    "    print(\"訓練用\", len(x_train))\n",
    "    print(\"検証用\", len(x_test))\n",
    "\n",
    "\n",
    "# リストが空でないか確認\n",
    "if not x_list or not y_list:\n",
    "    print(\"エラー: ファイルが見つかりません。\")\n",
    "else:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_list, y_list)\n",
    "    print(\"訓練用\", len(x_train))\n",
    "    print(\"検証用\", len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220eef9-ef0c-4df1-8e30-b4dcf37641d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#あしたためす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c1a3c-2ed2-49b3-b482-f29d424301df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 画像とラベルのディレクトリ\n",
    "image_dir = \"/path/to/images\"\n",
    "label_dir = \"/path/to/labels\"\n",
    "\n",
    "# 画像ファイルのリスト\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')] # 例として .jpg を使用\n",
    "\n",
    "# 画像ファイルの名前（拡張子を除く）に基づいてラベルファイルをマッチング\n",
    "data = [(os.path.join(image_dir, f), os.path.join(label_dir, f.replace('.jpg', '.txt'))) for f in image_files]\n",
    "\n",
    "# 画像とラベルのペアをトレーニングと検証用に分割\n",
    "train_data, val_data = train_test_split(data, test_size=0.2) # 例として20%を検証用に使用\n",
    "\n",
    "# 新しいディレクトリを作成\n",
    "for directory in [train_dir, val_dir]:\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# トレーニングデータのコピー\n",
    "for image, label in tqdm(train_data):\n",
    "    shutil.copyfile(image, os.path.join(train_dir, os.path.basename(image)))\n",
    "    shutil.copyfile(label, os.path.join(train_dir, os.path.basename(label)))\n",
    "\n",
    "# 検証データのコピー\n",
    "for image, label in tqdm(val_data):\n",
    "    shutil.copyfile(image, os.path.join(val_dir, os.path.basename(image)))\n",
    "    shutil.copyfile(label, os.path.join(val_dir, os.path.basename(label)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5de49e8-7447-4fb2-a050-6959f8203ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 194/194 [00:00<00:00, 1173.88it/s]\n",
      "100%|██████████████████████████████████████████| 66/66 [00:00<00:00, 988.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # トレーニング用と検証用ディレクトリのパス\n",
    "# train_dir = \"/home/yasumasa-tezuka/data_intern/train_data/images/train\"\n",
    "# val_dir = \"/home/yasumasa-tezuka/data_intern/train_data/labels/val\"\n",
    "\n",
    "# # 既存のディレクトリを削除し、新しく作成\n",
    "# for directory in [train_dir, val_dir]:\n",
    "#     if os.path.exists(directory):\n",
    "#         shutil.rmtree(directory)\n",
    "#     os.makedirs(directory)\n",
    "\n",
    "# # トレーニングデータのコピー\n",
    "# for f in tqdm(x_train + y_train):\n",
    "#     file_name = os.path.basename(f)\n",
    "#     shutil.copyfile(f, os.path.join(train_dir, file_name))\n",
    "\n",
    "# # 検証データのコピー\n",
    "# for f in tqdm(x_test + y_test):\n",
    "#     file_name = os.path.basename(f)\n",
    "#     shutil.copyfile(f, os.path.join(val_dir, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b8a2944-758b-473e-b4c8-ea9cf5e76f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data.yamlの変更\n",
    "yaml = \"\"\"\n",
    "train: /home/yasumasa-tezuka/data_intern/train_data/images_expansion/train\n",
    "val: /home/yasumasa-tezuka/data_intern/train_data/images_expansion/val\n",
    "\n",
    "nc: 1\n",
    "names: ['tree']\n",
    "\"\"\"\n",
    "\n",
    "#data.yamlの作成または上書き保存\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "  f.write(yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78703f2c-4b05-4372-8991-2393934e3026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 16083, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 16083 (delta 7), reused 12 (delta 1), pack-reused 16056\u001b[K\n",
      "Receiving objects: 100% (16083/16083), 14.71 MiB | 7.86 MiB/s, done.\n",
      "Resolving deltas: 100% (11035/11035), done.\n",
      "/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dff5d294-eee6-4e54-bb60-11564f892726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04 01:40:57.613391: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 01:40:57.613434: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 01:40:57.613468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/home/yasumasa-tezuka/data_intern/1~50annotation/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-247-g3f02fde Python-3.11.5 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12036MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "COMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Using '/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.\n",
      "\n",
      "Dataset not found ⚠️, missing paths ['/home/yasumasa-tezuka/data_intern/train_data/images/val']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/train.py\", line 648, in <module>\n",
      "    main(opt)\n",
      "  File \"/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/train.py\", line 537, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/train.py\", line 101, in train\n",
      "    loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)  # loggers instance\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/utils/loggers/__init__.py\", line 129, in __init__\n",
      "    self.comet_logger = CometLogger(self.opt, self.hyp)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/utils/loggers/comet/__init__.py\", line 98, in __init__\n",
      "    self.data_dict = self.check_dataset(self.opt.data)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/utils/loggers/comet/__init__.py\", line 244, in check_dataset\n",
      "    return check_dataset(data_file)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/utils/general.py\", line 527, in check_dataset\n",
      "    raise Exception('Dataset not found ❌')\n",
      "Exception: Dataset not found ❌\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml OfflineExperiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : [OfflineExperiment will get URL after upload]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name               : exp\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_experiment : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                        : 1 (151 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still saving offline stats to messages file before program termination (may take up to 120 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Starting saving the offline archive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m To upload this offline experiment, run:\n",
      "    comet upload /home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern/intern_YOLO.v5/yolov5/yolov5/yolov5/yolov5/yolov5/yolov5/.cometml-runs/a8f390900780473e9a28cf05a412ae7e.zip\n"
     ]
    }
   ],
   "source": [
    "# トレーニングの実行\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data /home/yasumasa-tezuka/data_intern/1~50annotation/data.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07dec42a-67bb-4a30-897a-56eb621deffa",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mクリック座標: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 画像ウィンドウを表示\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# マウスクリックイベントを設定\u001b[39;00m\n\u001b[1;32m     20\u001b[0m cv2\u001b[38;5;241m.\u001b[39msetMouseCallback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m, click_event)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 画像を読み込む\n",
    "image_path = '/home/yasumasa-tezuka/data_intern/train_data/images/0ace05a4-imori1.jpg'  # 画像の実際のファイルパスを指定してください\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# クリックした座標を保持するリスト\n",
    "click_coordinates = []\n",
    "\n",
    "# クリックイベントを処理するコールバック関数\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        click_coordinates.append((x, y))\n",
    "        print(f\"クリック座標: x={x}, y={y}\")\n",
    "\n",
    "# 画像ウィンドウを表示\n",
    "cv2.imshow('Image', image)\n",
    "\n",
    "# マウスクリックイベントを設定\n",
    "cv2.setMouseCallback('Image', click_event)\n",
    "\n",
    "# 画像ウィンドウが閉じられるまで待機\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# クリックした座標を表示\n",
    "print(\"クリックした座標:\", click_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "faec1182-af63-48ad-8bfc-bb5d459e2c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[204 170 140]\n",
      "  [205 171 141]\n",
      "  [207 173 143]\n",
      "  ...\n",
      "  [  0  13   2]\n",
      "  [  0  17   6]\n",
      "  [  6  23  12]]\n",
      "\n",
      " [[204 170 140]\n",
      "  [205 171 141]\n",
      "  [206 172 142]\n",
      "  ...\n",
      "  [  7  24  13]\n",
      "  [ 12  29  18]\n",
      "  [ 19  36  25]]\n",
      "\n",
      " [[204 170 140]\n",
      "  [205 171 141]\n",
      "  [206 172 142]\n",
      "  ...\n",
      "  [  5  22  11]\n",
      "  [ 10  26  15]\n",
      "  [ 16  32  21]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 53  53  39]\n",
      "  [ 53  53  39]\n",
      "  [ 54  54  42]\n",
      "  ...\n",
      "  [ 67  84  87]\n",
      "  [ 72  87  90]\n",
      "  [ 67  82  85]]\n",
      "\n",
      " [[ 51  54  39]\n",
      "  [ 52  55  40]\n",
      "  [ 52  55  40]\n",
      "  ...\n",
      "  [ 68  83  86]\n",
      "  [ 69  81  85]\n",
      "  [ 61  73  77]]\n",
      "\n",
      " [[ 51  54  39]\n",
      "  [ 52  55  40]\n",
      "  [ 53  56  41]\n",
      "  ...\n",
      "  [ 72  87  90]\n",
      "  [ 71  83  87]\n",
      "  [ 61  73  77]]]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(image)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 画像ウィンドウを表示\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# マウスクリックイベントを設定\u001b[39;00m\n\u001b[1;32m     20\u001b[0m cv2\u001b[38;5;241m.\u001b[39msetMouseCallback(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m, click_event)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 画像を読み込む\n",
    "image_path = '/home/yasumasa-tezuka/data_intern/train_data/images/0ace05a4-imori1.jpg'  # 画像の実際のファイルパスを指定してください\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# クリックした座標を保持するリスト\n",
    "click_coordinates = []\n",
    "\n",
    "# クリックイベントを処理するコールバック関数\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        click_coordinates.append((x, y))\n",
    "        print(f\"クリック座標: x={x}, y={y}\")\n",
    "print(image)\n",
    "# 画像ウィンドウを表示\n",
    "cv2.imshow('Image', image)\n",
    "\n",
    "# マウスクリックイベントを設定\n",
    "cv2.setMouseCallback('Image', click_event)\n",
    "\n",
    "# 画像ウィンドウが閉じられるまで待機\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# クリックした座標を表示\n",
    "print(\"クリックした座標:\", click_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8c62d-a272-4fae-bcaa-e05e2bf73e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
