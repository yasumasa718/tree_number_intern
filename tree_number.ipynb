{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d34048-0e54-4e41-91da-71378c2c601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 22:28:48.199862: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-13 22:28:48.199897: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-13 22:28:48.199923: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-13 22:28:48.205980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 22:28:48.865117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#ライブラリ\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlowの警告とエラーメッセージの抑制\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df0da7d-de2c-4ab9-b6f5-b4a26fb57287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number_github/tree_number_intern\n",
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    " # 現在の作業ディレクトリを取得\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 結果を出力\n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0defeb9-ee11-4cd8-a5d6-588dfa40b9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画像が格納されているディレクトリのパス\n",
    "image_directory = '/home/yasumasa-tezuka/NeuroDive_日揮インターン/intern_tree_number/intern_tree_number/tree_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be538da-025f-47f6-9999-5dea14b12514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images processed: 1131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 画像サイズの設定\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# 画像の前処理関数\n",
    "def preprocess_image(image_path):\n",
    "    # 画像を読み込み、サイズを変更\n",
    "    image = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    # 画像を配列に変換\n",
    "    image = img_to_array(image)\n",
    "    \n",
    "    # 正規化\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 画像パスを取得\n",
    "image_paths = glob.glob(os.path.join(image_directory, '*.jpg'))\n",
    "\n",
    "# 画像を前処理してリストに追加\n",
    "processed_images = [preprocess_image(path) for path in image_paths]\n",
    "\n",
    "# 結果の確認\n",
    "print(f'Total images processed: {len(processed_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438c071c-6385-4cec-9eb3-a0fe751071ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# アノテーションデータの読み込み\n",
    "def load_annotation(image_path):\n",
    "    # アノテーションデータのファイルパスを生成\n",
    "    # 例: image_pathが'path/to/image_0001.jpg'なら、annotation_pathは'path/to/annotation_0001.json'\n",
    "    annotation_path = image_path.replace('.jpg', '.json')  # JSONの場合\n",
    "\n",
    "    # アノテーションファイルを読み込む\n",
    "    # 実際の読み込み方法はアノテーションの形式に依存します\n",
    "    # 例: JSONファイルの場合は、json.loadを使用して読み込む\n",
    "\n",
    "    return annotation_data\n",
    "\n",
    "# トレーニング用の画像パスを取得（0001～0050）\n",
    "train_image_paths = glob.glob(os.path.join(image_directory, 'image_00[0-4][0-9].jpg')) + glob.glob(os.path.join(image_directory, 'image_0050.jpg'))\n",
    "\n",
    "# 画像とアノテーションを読み込む\n",
    "train_images = [preprocess_image(path) for path in train_image_paths]\n",
    "train_annotations = [load_annotation(path) for path in train_image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4e324-b5d4-46b1-9afa-5094965a1d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
